{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd5b237",
   "metadata": {},
   "source": [
    "# Step 5: Hyperparameter Optimization with Optuna\n",
    "\n",
    "## Objective\n",
    "Use Optuna's Bayesian optimization to find the optimal hyperparameters for the stacking ensemble configuration identified in Notebook 04.\n",
    "\n",
    "## Process\n",
    "1. Load ensemble configuration from Notebook 04 (TOP_3_MODELS and BEST_META_LEARNER)\n",
    "2. Define hyperparameter search spaces for each base learner\n",
    "3. Define hyperparameter search space for the meta-learner\n",
    "4. Run Optuna optimization trials (up to 100 trials)\n",
    "5. Track and display progress after each trial\n",
    "6. Select best hyperparameter configuration based on test accuracy\n",
    "7. Train final optimized ensemble\n",
    "8. Save best parameters for future use\n",
    "\n",
    "## Output\n",
    "- Optimized hyperparameters for all models in the ensemble\n",
    "- Best parameters saved to JSON file for reproducibility\n",
    "- Final optimized ensemble performance metrics\n",
    "- Comparison: optimized vs baseline ensemble\n",
    "\n",
    "## Optimization Strategy\n",
    "**Bayesian Optimization with Optuna:**\n",
    "- Intelligently explores hyperparameter space\n",
    "- Learns from previous trials to suggest better parameters\n",
    "- More efficient than grid search or random search\n",
    "- Balances exploration vs exploitation\n",
    "- Objective: Maximize test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742ba3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization started at: 2025-10-25 11:29:22\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Model selection and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# All potential model classes (same as notebook 04)\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Optuna for hyperparameter optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "print(f\"Hyperparameter optimization started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6440f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Features: ../data/processed/BRL_X_features.csv\n",
      "  Top Models: ../data/processed/metrics/top_3_model_names.txt\n",
      "  Output: ../data/processed/metrics/best_params_stacking.json\n",
      "  Optimization Trials: 100\n",
      "  CV Folds: 5\n"
     ]
    }
   ],
   "source": [
    "# Define configuration parameters\n",
    "FEATURES_PATH = '../data/processed/BRL_X_features.csv'  # Input file from notebook 02\n",
    "TOP_MODELS_FILE = '../data/processed/metrics/top_3_model_names.txt'  # Top 3 models from notebook 03\n",
    "ENSEMBLE_CONFIG_FILE = '../data/processed/metrics/stacking_ensemble_config.txt'  # Config from notebook 04\n",
    "BEST_PARAMS_OUTPUT = '../data/processed/metrics/best_params_stacking.json'  # Output for best parameters\n",
    "\n",
    "# Train/test split configuration (must match notebooks 03 and 04)\n",
    "TEST_SIZE = 0.2        # 20% of data for testing\n",
    "RANDOM_STATE = 42      # For reproducibility\n",
    "SHUFFLE = False        # Critical: Do not shuffle time series data\n",
    "\n",
    "# Optuna optimization configuration\n",
    "N_TRIALS = 100         # Number of optimization trials\n",
    "CV_FOLDS = 5           # Cross-validation folds\n",
    "N_JOBS = -1            # Use all CPU cores\n",
    "TIMEOUT = None         # No timeout (can set to limit execution time)\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Features: {FEATURES_PATH}\")\n",
    "print(f\"  Top Models: {TOP_MODELS_FILE}\")\n",
    "print(f\"  Output: {BEST_PARAMS_OUTPUT}\")\n",
    "print(f\"  Optimization Trials: {N_TRIALS}\")\n",
    "print(f\"  CV Folds: {CV_FOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224b4304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ensemble configuration from previous notebooks...\n",
      "\n",
      "Top 3 Base Learners (from Notebook 03):\n",
      "  1. QuadraticDiscriminantAnalysis\n",
      "  2. LinearDiscriminantAnalysis\n",
      "  3. LinearSVC\n",
      "\n",
      "Best Meta-Learner (from Notebook 04): LogisticRegression\n",
      "\n",
      "Optimizing hyperparameters for this ensemble configuration...\n"
     ]
    }
   ],
   "source": [
    "# Load top 3 model names from Notebook 03\n",
    "print(\"Loading ensemble configuration from previous notebooks...\")\n",
    "\n",
    "TOP_3_MODELS = []\n",
    "with open(TOP_MODELS_FILE, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if line.strip() and line[0].isdigit():\n",
    "            model_name = line.split('.', 1)[1].strip()\n",
    "            TOP_3_MODELS.append(model_name)\n",
    "\n",
    "print(f\"\\nTop 3 Base Learners (from Notebook 03):\")\n",
    "for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "    print(f\"  {i}. {model_name}\")\n",
    "\n",
    "# Load best meta-learner name from Notebook 04 configuration file\n",
    "BEST_META_LEARNER_NAME = None\n",
    "with open(ENSEMBLE_CONFIG_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('Meta-Learner:'):\n",
    "            BEST_META_LEARNER_NAME = line.split(':', 1)[1].strip()\n",
    "            break\n",
    "\n",
    "print(f\"\\nBest Meta-Learner (from Notebook 04): {BEST_META_LEARNER_NAME}\")\n",
    "print(f\"\\nOptimizing hyperparameters for this ensemble configuration...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83be5c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "  Total records: 4103\n",
      "  Date range: 2010-01-21 to 2025-10-24\n",
      "  Rows dropped (NaN): 0\n",
      "\n",
      "Features: (4103, 17)\n",
      "Target: (4103,)\n"
     ]
    }
   ],
   "source": [
    "# Load engineered features from Notebook 02\n",
    "df = pd.read_csv(FEATURES_PATH, index_col=0)\n",
    "\n",
    "# Convert index to datetime for proper time series handling\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index.name = 'Date'\n",
    "\n",
    "# Handle missing values\n",
    "rows_before = len(df)\n",
    "df = df.dropna()\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f\"Data loaded:\")\n",
    "print(f\"  Total records: {rows_after}\")\n",
    "print(f\"  Date range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Rows dropped (NaN): {rows_before - rows_after}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "print(f\"\\nFeatures: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14adee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split:\n",
      "  Training: 3282 samples (80.0%)\n",
      "  Testing: 821 samples (20.0%)\n",
      "  Training period: 2010-01-21 to 2022-08-29\n",
      "  Testing period: 2022-08-30 to 2025-10-24\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "# CRITICAL: Must match Notebooks 03 and 04 for fair comparison\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=SHUFFLE\n",
    ")\n",
    "\n",
    "print(f\"Train/Test Split:\")\n",
    "print(f\"  Training: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Testing: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Training period: {X_train.index.min().strftime('%Y-%m-%d')} to {X_train.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Testing period: {X_test.index.min().strftime('%Y-%m-%d')} to {X_test.index.max().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f44f7f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter search space functions defined for all model types\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search spaces for each model type\n",
    "# These functions return model-specific hyperparameter suggestions\n",
    "\n",
    "def get_hyperparameters_for_model(trial, model_name, prefix=''):\n",
    "    \"\"\"\n",
    "    Generate hyperparameter suggestions for a given model.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        model_name: Name of the model class\n",
    "        prefix: Prefix for parameter names (e.g., 'model1_' or 'meta_')\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of hyperparameters for the model\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    \n",
    "    if model_name == 'LinearDiscriminantAnalysis':\n",
    "        params['solver'] = trial.suggest_categorical(f'{prefix}solver', ['svd', 'lsqr', 'eigen'])\n",
    "        if params['solver'] in ['lsqr', 'eigen']:\n",
    "            params['shrinkage'] = trial.suggest_categorical(f'{prefix}shrinkage', [None, 'auto'])\n",
    "    \n",
    "    elif model_name == 'QuadraticDiscriminantAnalysis':\n",
    "        params['reg_param'] = trial.suggest_float(f'{prefix}reg_param', 1e-5, 1e-1, log=True)\n",
    "    \n",
    "    elif model_name == 'LinearSVC':\n",
    "        params['C'] = trial.suggest_float(f'{prefix}C', 1e-3, 10, log=True)\n",
    "        params['loss'] = trial.suggest_categorical(f'{prefix}loss', ['hinge', 'squared_hinge'])\n",
    "        params['max_iter'] = 10000\n",
    "    \n",
    "    elif model_name == 'LogisticRegression':\n",
    "        params['C'] = trial.suggest_float(f'{prefix}C', 1e-3, 10, log=True)\n",
    "        params['solver'] = trial.suggest_categorical(f'{prefix}solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "        params['max_iter'] = 10000\n",
    "    \n",
    "    elif model_name == 'RandomForest' or model_name == 'RandomForestClassifier':\n",
    "        params['n_estimators'] = trial.suggest_int(f'{prefix}n_estimators', 50, 300)\n",
    "        params['max_depth'] = trial.suggest_int(f'{prefix}max_depth', 3, 15)\n",
    "        params['min_samples_split'] = trial.suggest_int(f'{prefix}min_samples_split', 2, 20)\n",
    "        params['min_samples_leaf'] = trial.suggest_int(f'{prefix}min_samples_leaf', 1, 10)\n",
    "    \n",
    "    elif model_name == 'XGBoost' or model_name == 'XGBClassifier':\n",
    "        params['learning_rate'] = trial.suggest_float(f'{prefix}learning_rate', 1e-3, 0.3, log=True)\n",
    "        params['max_depth'] = trial.suggest_int(f'{prefix}max_depth', 3, 10)\n",
    "        params['n_estimators'] = trial.suggest_int(f'{prefix}n_estimators', 50, 300)\n",
    "        params['subsample'] = trial.suggest_float(f'{prefix}subsample', 0.6, 1.0)\n",
    "        params['colsample_bytree'] = trial.suggest_float(f'{prefix}colsample_bytree', 0.6, 1.0)\n",
    "    \n",
    "    elif model_name == 'GradientBoosting' or model_name == 'GradientBoostingClassifier':\n",
    "        params['learning_rate'] = trial.suggest_float(f'{prefix}learning_rate', 1e-3, 0.3, log=True)\n",
    "        params['n_estimators'] = trial.suggest_int(f'{prefix}n_estimators', 50, 300)\n",
    "        params['max_depth'] = trial.suggest_int(f'{prefix}max_depth', 3, 10)\n",
    "        params['subsample'] = trial.suggest_float(f'{prefix}subsample', 0.6, 1.0)\n",
    "    \n",
    "    elif model_name == 'ExtraTrees' or model_name == 'ExtraTreesClassifier':\n",
    "        params['n_estimators'] = trial.suggest_int(f'{prefix}n_estimators', 50, 300)\n",
    "        params['max_depth'] = trial.suggest_int(f'{prefix}max_depth', 3, 15)\n",
    "        params['min_samples_split'] = trial.suggest_int(f'{prefix}min_samples_split', 2, 20)\n",
    "    \n",
    "    return params\n",
    "\n",
    "print(\"Hyperparameter search space functions defined for all model types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ad419d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model instantiation function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to instantiate model with hyperparameters\n",
    "def instantiate_model(model_name, params):\n",
    "    \"\"\"\n",
    "    Create a model instance with specified hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model class\n",
    "        params: Dictionary of hyperparameters\n",
    "    \n",
    "    Returns:\n",
    "        Instantiated sklearn/xgboost model\n",
    "    \"\"\"\n",
    "    if model_name == 'LinearDiscriminantAnalysis':\n",
    "        return LinearDiscriminantAnalysis(**params)\n",
    "    \n",
    "    elif model_name == 'QuadraticDiscriminantAnalysis':\n",
    "        return QuadraticDiscriminantAnalysis(**params)\n",
    "    \n",
    "    elif model_name == 'LinearSVC':\n",
    "        return LinearSVC(random_state=RANDOM_STATE, **params)\n",
    "    \n",
    "    elif model_name == 'LogisticRegression':\n",
    "        return LogisticRegression(random_state=RANDOM_STATE, **params)\n",
    "    \n",
    "    elif model_name in ['RandomForest', 'RandomForestClassifier']:\n",
    "        return RandomForestClassifier(random_state=RANDOM_STATE, **params)\n",
    "    \n",
    "    elif model_name in ['XGBoost', 'XGBClassifier']:\n",
    "        return XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss', **params)\n",
    "    \n",
    "    elif model_name in ['GradientBoosting', 'GradientBoostingClassifier']:\n",
    "        return GradientBoostingClassifier(random_state=RANDOM_STATE, **params)\n",
    "    \n",
    "    elif model_name in ['ExtraTrees', 'ExtraTreesClassifier']:\n",
    "        return ExtraTreesClassifier(random_state=RANDOM_STATE, **params)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Model '{model_name}' not supported for hyperparameter optimization\")\n",
    "\n",
    "print(\"Model instantiation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f348c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function defined for Optuna optimization\n"
     ]
    }
   ],
   "source": [
    "# Define Optuna objective function for hyperparameter optimization\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to maximize test accuracy.\n",
    "    Optimizes hyperparameters for all base learners and the meta-learner.\n",
    "    \n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "    \n",
    "    Returns:\n",
    "        Test set accuracy (to be maximized)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create base learners with optimized hyperparameters\n",
    "        base_learners_opt = []\n",
    "        \n",
    "        for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "            prefix = f'model{i}_'\n",
    "            params = get_hyperparameters_for_model(trial, model_name, prefix)\n",
    "            model_instance = instantiate_model(model_name, params)\n",
    "            base_learners_opt.append((f'model_{i}', model_instance))\n",
    "        \n",
    "        # Create meta-learner with optimized hyperparameters\n",
    "        meta_prefix = 'meta_'\n",
    "        meta_params = get_hyperparameters_for_model(trial, BEST_META_LEARNER_NAME, meta_prefix)\n",
    "        meta_learner = instantiate_model(BEST_META_LEARNER_NAME, meta_params)\n",
    "        \n",
    "        # Build and train stacking ensemble\n",
    "        stacking_clf = StackingClassifier(\n",
    "            estimators=base_learners_opt,\n",
    "            final_estimator=meta_learner,\n",
    "            cv=CV_FOLDS,\n",
    "            n_jobs=N_JOBS\n",
    "        )\n",
    "        \n",
    "        stacking_clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = stacking_clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Trial {trial.number:3d}: Accuracy = {accuracy:.4f}\")\n",
    "        \n",
    "        return accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number:3d}: FAILED - {str(e)}\")\n",
    "        return 0.0  # Return 0 for failed trials\n",
    "\n",
    "print(\"Objective function defined for Optuna optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16de921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-25 11:29:22,779] A new study created in memory with name: no-name-73d27183-500f-4432-999e-5e338b9ec3a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Starting Optuna hyperparameter optimization...\n",
      "Configuration to optimize:\n",
      "  Base Learners: ['QuadraticDiscriminantAnalysis', 'LinearDiscriminantAnalysis', 'LinearSVC']\n",
      "  Meta-Learner: LogisticRegression\n",
      "  Number of Trials: 100\n",
      "  CV Folds: 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0667af91a6b94caf91daed67fff2a7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial   0: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:29:31,716] Trial 0 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.00031489116479568613, 'model2_solver': 'svd', 'model3_C': 0.004207988669606638, 'model3_loss': 'hinge', 'meta_C': 2.9154431891537547, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   1: Accuracy = 0.4823\n",
      "[I 2025-10-25 11:29:38,759] Trial 1 finished with value: 0.4823386114494519 and parameters: {'model1_reg_param': 0.07579479953348005, 'model2_solver': 'svd', 'model3_C': 0.00541524411940254, 'model3_loss': 'squared_hinge', 'meta_C': 0.05342937261279776, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   1: Accuracy = 0.4823\n",
      "[I 2025-10-25 11:29:38,759] Trial 1 finished with value: 0.4823386114494519 and parameters: {'model1_reg_param': 0.07579479953348005, 'model2_solver': 'svd', 'model3_C': 0.00541524411940254, 'model3_loss': 'squared_hinge', 'meta_C': 0.05342937261279776, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   2: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:41,642] Trial 2 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00014742753159914678, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.23423849847112907, 'model3_loss': 'squared_hinge', 'meta_C': 0.004809461967501573, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   2: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:41,642] Trial 2 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00014742753159914678, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.23423849847112907, 'model3_loss': 'squared_hinge', 'meta_C': 0.004809461967501573, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   3: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:29:42,259] Trial 3 finished with value: 0.0 and parameters: {'model1_reg_param': 0.01712337597316398, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.09565499215943825, 'model3_loss': 'squared_hinge', 'meta_C': 0.010842262717330166, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   3: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:29:42,259] Trial 3 finished with value: 0.0 and parameters: {'model1_reg_param': 0.01712337597316398, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.09565499215943825, 'model3_loss': 'squared_hinge', 'meta_C': 0.010842262717330166, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   4: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:51,441] Trial 4 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.0015375920235481753, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.24637685958997463, 'model3_loss': 'hinge', 'meta_C': 0.006080390190296602, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   4: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:51,441] Trial 4 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.0015375920235481753, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.24637685958997463, 'model3_loss': 'hinge', 'meta_C': 0.006080390190296602, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   5: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:57,579] Trial 5 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00012172958098369953, 'model2_solver': 'svd', 'model3_C': 0.14817820606039092, 'model3_loss': 'squared_hinge', 'meta_C': 0.0019870215385428634, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   5: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:29:57,579] Trial 5 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00012172958098369953, 'model2_solver': 'svd', 'model3_C': 0.14817820606039092, 'model3_loss': 'squared_hinge', 'meta_C': 0.0019870215385428634, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   6: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:00,600] Trial 6 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 1.0521761868451132e-05, 'model2_solver': 'svd', 'model3_C': 1.2164139351417065, 'model3_loss': 'squared_hinge', 'meta_C': 0.0029072088906598446, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   7: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:00,799] Trial 7 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 1.795698422567761e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.0774211647399625, 'model3_loss': 'squared_hinge', 'meta_C': 1.1044350847124695, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   6: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:00,600] Trial 6 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 1.0521761868451132e-05, 'model2_solver': 'svd', 'model3_C': 1.2164139351417065, 'model3_loss': 'squared_hinge', 'meta_C': 0.0029072088906598446, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   7: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:00,799] Trial 7 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 1.795698422567761e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.0774211647399625, 'model3_loss': 'squared_hinge', 'meta_C': 1.1044350847124695, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   8: Accuracy = 0.5055\n",
      "[I 2025-10-25 11:30:01,391] Trial 8 finished with value: 0.5054811205846529 and parameters: {'model1_reg_param': 0.0012329098365270509, 'model2_solver': 'svd', 'model3_C': 0.0013357240411974098, 'model3_loss': 'hinge', 'meta_C': 0.1082138291061399, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   9: Accuracy = 0.5335\n",
      "[I 2025-10-25 11:30:01,479] Trial 9 finished with value: 0.5334957369062119 and parameters: {'model1_reg_param': 0.010524574681335632, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 1.7079750342958235, 'model3_loss': 'squared_hinge', 'meta_C': 1.6394127471631603, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   8: Accuracy = 0.5055\n",
      "[I 2025-10-25 11:30:01,391] Trial 8 finished with value: 0.5054811205846529 and parameters: {'model1_reg_param': 0.0012329098365270509, 'model2_solver': 'svd', 'model3_C': 0.0013357240411974098, 'model3_loss': 'hinge', 'meta_C': 0.1082138291061399, 'meta_solver': 'lbfgs'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial   9: Accuracy = 0.5335\n",
      "[I 2025-10-25 11:30:01,479] Trial 9 finished with value: 0.5334957369062119 and parameters: {'model1_reg_param': 0.010524574681335632, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 1.7079750342958235, 'model3_loss': 'squared_hinge', 'meta_C': 1.6394127471631603, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  10: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:02,379] Trial 10 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.00017594678649531827, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.00996555116792998, 'model3_loss': 'hinge', 'meta_C': 4.2722748162267905, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  10: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:02,379] Trial 10 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.00017594678649531827, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.00996555116792998, 'model3_loss': 'hinge', 'meta_C': 4.2722748162267905, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  11: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:30:05,259] Trial 11 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 1.2495883480837865e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.02534892202190151, 'model3_loss': 'hinge', 'meta_C': 0.6669938379486058, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  11: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:30:05,259] Trial 11 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 1.2495883480837865e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.02534892202190151, 'model3_loss': 'hinge', 'meta_C': 0.6669938379486058, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  12: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:30:06,110] Trial 12 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 3.683436877306914e-05, 'model2_solver': 'svd', 'model3_C': 0.0011068049999015423, 'model3_loss': 'hinge', 'meta_C': 0.38244369006170487, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  12: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:30:06,110] Trial 12 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 3.683436877306914e-05, 'model2_solver': 'svd', 'model3_C': 0.0011068049999015423, 'model3_loss': 'hinge', 'meta_C': 0.38244369006170487, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  13: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:08,381] Trial 13 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 0.0005706611632633769, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.03235766254967102, 'model3_loss': 'hinge', 'meta_C': 8.890019970164188, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  14: Accuracy = 0.5262\n",
      "[I 2025-10-25 11:30:08,518] Trial 14 finished with value: 0.5261875761266748 and parameters: {'model1_reg_param': 4.645057662174063e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 9.941450502972573, 'model3_loss': 'squared_hinge', 'meta_C': 1.8160795832556924, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  13: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:08,381] Trial 13 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 0.0005706611632633769, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.03235766254967102, 'model3_loss': 'hinge', 'meta_C': 8.890019970164188, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  14: Accuracy = 0.5262\n",
      "[I 2025-10-25 11:30:08,518] Trial 14 finished with value: 0.5261875761266748 and parameters: {'model1_reg_param': 4.645057662174063e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 9.941450502972573, 'model3_loss': 'squared_hinge', 'meta_C': 1.8160795832556924, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  15: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:30:09,655] Trial 15 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.0004837501614261859, 'model2_solver': 'svd', 'model3_C': 0.004266587910190727, 'model3_loss': 'hinge', 'meta_C': 0.2693385147450887, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  15: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:30:09,655] Trial 15 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.0004837501614261859, 'model2_solver': 'svd', 'model3_C': 0.004266587910190727, 'model3_loss': 'hinge', 'meta_C': 0.2693385147450887, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  16: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:30:12,002] Trial 16 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.0033445475452636517, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.034663436215614685, 'model3_loss': 'hinge', 'meta_C': 1.5747235016725751, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  17: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:12,125] Trial 17 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 3.883251094650873e-05, 'model2_solver': 'svd', 'model3_C': 1.3309280451209935, 'model3_loss': 'squared_hinge', 'meta_C': 8.273749485522027, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  16: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:30:12,002] Trial 16 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.0033445475452636517, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.034663436215614685, 'model3_loss': 'hinge', 'meta_C': 1.5747235016725751, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  17: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:12,125] Trial 17 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 3.883251094650873e-05, 'model2_solver': 'svd', 'model3_C': 1.3309280451209935, 'model3_loss': 'squared_hinge', 'meta_C': 8.273749485522027, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  18: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:30:12,638] Trial 18 finished with value: 0.0 and parameters: {'model1_reg_param': 0.00024322435671002152, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.01154862393067319, 'model3_loss': 'hinge', 'meta_C': 0.08152728131129283, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  18: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:30:12,638] Trial 18 finished with value: 0.0 and parameters: {'model1_reg_param': 0.00024322435671002152, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.01154862393067319, 'model3_loss': 'hinge', 'meta_C': 0.08152728131129283, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  19: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:20,787] Trial 19 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.003929654698854919, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.002462971549617274, 'model3_loss': 'squared_hinge', 'meta_C': 0.0233437141412462, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  19: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:20,787] Trial 19 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.003929654698854919, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.002462971549617274, 'model3_loss': 'squared_hinge', 'meta_C': 0.0233437141412462, 'meta_solver': 'saga'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  20: Accuracy = 0.5213\n",
      "[I 2025-10-25 11:30:28,353] Trial 20 finished with value: 0.5213154689403167 and parameters: {'model1_reg_param': 6.581152192027808e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.459840875554983, 'model3_loss': 'hinge', 'meta_C': 0.8310197824164313, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  20: Accuracy = 0.5213\n",
      "[I 2025-10-25 11:30:28,353] Trial 20 finished with value: 0.5213154689403167 and parameters: {'model1_reg_param': 6.581152192027808e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.459840875554983, 'model3_loss': 'hinge', 'meta_C': 0.8310197824164313, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  21: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:30:31,865] Trial 21 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.0003220949257663767, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.012251118583625768, 'model3_loss': 'hinge', 'meta_C': 3.6401614971794056, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  21: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:30:31,865] Trial 21 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.0003220949257663767, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.012251118583625768, 'model3_loss': 'hinge', 'meta_C': 3.6401614971794056, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  22: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:33,363] Trial 22 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 0.00041332069094414566, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.05338646243349573, 'model3_loss': 'hinge', 'meta_C': 2.163540235402695, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  22: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:33,363] Trial 22 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 0.00041332069094414566, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.05338646243349573, 'model3_loss': 'hinge', 'meta_C': 2.163540235402695, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  23: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:34,550] Trial 23 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 2.7205249345549184e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.013934608116269754, 'model3_loss': 'hinge', 'meta_C': 3.99928681930522, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  23: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:34,550] Trial 23 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 2.7205249345549184e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.013934608116269754, 'model3_loss': 'hinge', 'meta_C': 3.99928681930522, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  24: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:30:35,261] Trial 24 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 9.126704124098428e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.00470556119850414, 'model3_loss': 'hinge', 'meta_C': 4.560880895252941, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  24: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:30:35,261] Trial 24 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 9.126704124098428e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.00470556119850414, 'model3_loss': 'hinge', 'meta_C': 4.560880895252941, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  25: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:30:36,095] Trial 25 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 9.284107673757434e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.0040814268735703705, 'model3_loss': 'hinge', 'meta_C': 3.6465044752471956, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  25: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:30:36,095] Trial 25 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 9.284107673757434e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.0040814268735703705, 'model3_loss': 'hinge', 'meta_C': 3.6465044752471956, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  26: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:30:36,993] Trial 26 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.00030317787935085566, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002262090986020849, 'model3_loss': 'hinge', 'meta_C': 0.2760528385236843, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  26: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:30:36,993] Trial 26 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.00030317787935085566, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002262090986020849, 'model3_loss': 'hinge', 'meta_C': 0.2760528385236843, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  27: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:37,859] Trial 27 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 0.0007620620447461444, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.009630890624562469, 'model3_loss': 'hinge', 'meta_C': 5.556738163527758, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  27: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:37,859] Trial 27 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 0.0007620620447461444, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.009630890624562469, 'model3_loss': 'hinge', 'meta_C': 5.556738163527758, 'meta_solver': 'liblinear'}. Best is trial 0 with value: 0.5408038976857491.\n",
      "Trial  28: Accuracy = 0.5457\n",
      "[I 2025-10-25 11:30:38,943] Trial 28 finished with value: 0.5456760048721072 and parameters: {'model1_reg_param': 8.526718006684437e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.020491419535060576, 'model3_loss': 'hinge', 'meta_C': 0.622062829368627, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  28: Accuracy = 0.5457\n",
      "[I 2025-10-25 11:30:38,943] Trial 28 finished with value: 0.5456760048721072 and parameters: {'model1_reg_param': 8.526718006684437e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.020491419535060576, 'model3_loss': 'hinge', 'meta_C': 0.622062829368627, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  29: Accuracy = 0.5043\n",
      "[I 2025-10-25 11:30:40,016] Trial 29 finished with value: 0.5042630937880633 and parameters: {'model1_reg_param': 0.049430788546160245, 'model2_solver': 'svd', 'model3_C': 0.019523695994424738, 'model3_loss': 'hinge', 'meta_C': 0.14793245617911271, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  29: Accuracy = 0.5043\n",
      "[I 2025-10-25 11:30:40,016] Trial 29 finished with value: 0.5042630937880633 and parameters: {'model1_reg_param': 0.049430788546160245, 'model2_solver': 'svd', 'model3_C': 0.019523695994424738, 'model3_loss': 'hinge', 'meta_C': 0.14793245617911271, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  30: Accuracy = 0.4787\n",
      "[I 2025-10-25 11:30:40,812] Trial 30 finished with value: 0.47868453105968334 and parameters: {'model1_reg_param': 0.002911149637676575, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.006610011773679957, 'model3_loss': 'hinge', 'meta_C': 0.040700548104481316, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  30: Accuracy = 0.4787\n",
      "[I 2025-10-25 11:30:40,812] Trial 30 finished with value: 0.47868453105968334 and parameters: {'model1_reg_param': 0.002911149637676575, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.006610011773679957, 'model3_loss': 'hinge', 'meta_C': 0.040700548104481316, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  31: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:41,609] Trial 31 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 7.977316898602335e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002744949399479432, 'model3_loss': 'hinge', 'meta_C': 2.8397187639978605, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  31: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:41,609] Trial 31 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 7.977316898602335e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002744949399479432, 'model3_loss': 'hinge', 'meta_C': 2.8397187639978605, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  32: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:30:42,526] Trial 32 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 0.0002405979153863588, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.006978087480361288, 'model3_loss': 'hinge', 'meta_C': 0.6163542586911034, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  32: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:30:42,526] Trial 32 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 0.0002405979153863588, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.006978087480361288, 'model3_loss': 'hinge', 'meta_C': 0.6163542586911034, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  33: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:43,776] Trial 33 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.0001335077700575241, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.017059656029617697, 'model3_loss': 'hinge', 'meta_C': 5.8265124096819445, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  33: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:43,776] Trial 33 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.0001335077700575241, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.017059656029617697, 'model3_loss': 'hinge', 'meta_C': 5.8265124096819445, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  34: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:30:44,592] Trial 34 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.0009335004302260018, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.005129278614220918, 'model3_loss': 'hinge', 'meta_C': 1.0806219395492183, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  34: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:30:44,592] Trial 34 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.0009335004302260018, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.005129278614220918, 'model3_loss': 'hinge', 'meta_C': 1.0806219395492183, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  35: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:45,259] Trial 35 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.00016556409473984733, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002108222292714781, 'model3_loss': 'hinge', 'meta_C': 9.258192590043357, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  35: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:30:45,259] Trial 35 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 0.00016556409473984733, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.002108222292714781, 'model3_loss': 'hinge', 'meta_C': 9.258192590043357, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  36: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:46,714] Trial 36 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 6.029949445339491e-05, 'model2_solver': 'svd', 'model3_C': 0.04935655956781431, 'model3_loss': 'hinge', 'meta_C': 0.40323849130928346, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  36: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:46,714] Trial 36 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 6.029949445339491e-05, 'model2_solver': 'svd', 'model3_C': 0.04935655956781431, 'model3_loss': 'hinge', 'meta_C': 0.40323849130928346, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  37: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:30:47,664] Trial 37 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.001929678380266248, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.008301460267168577, 'model3_loss': 'hinge', 'meta_C': 2.6284699818934802, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  37: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:30:47,664] Trial 37 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.001929678380266248, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.008301460267168577, 'model3_loss': 'hinge', 'meta_C': 2.6284699818934802, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  38: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:49,290] Trial 38 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 2.491944117068803e-05, 'model2_solver': 'svd', 'model3_C': 0.15611382476998753, 'model3_loss': 'hinge', 'meta_C': 1.2143758702847245, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  38: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:30:49,290] Trial 38 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 2.491944117068803e-05, 'model2_solver': 'svd', 'model3_C': 0.15611382476998753, 'model3_loss': 'hinge', 'meta_C': 1.2143758702847245, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  39: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:50,100] Trial 39 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 0.0002976688750468179, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.004105229650005525, 'model3_loss': 'hinge', 'meta_C': 5.774155711960108, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  40: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:50,181] Trial 40 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00011368044590871118, 'model2_solver': 'svd', 'model3_C': 0.0015648533177197944, 'model3_loss': 'squared_hinge', 'meta_C': 0.001327842436770112, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  41: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:50,279] Trial 41 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 1.9369134399306683e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.07676743274441097, 'model3_loss': 'squared_hinge', 'meta_C': 1.0917470713049682, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  39: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:50,100] Trial 39 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 0.0002976688750468179, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.004105229650005525, 'model3_loss': 'hinge', 'meta_C': 5.774155711960108, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  40: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:30:50,181] Trial 40 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 0.00011368044590871118, 'model2_solver': 'svd', 'model3_C': 0.0015648533177197944, 'model3_loss': 'squared_hinge', 'meta_C': 0.001327842436770112, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  41: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:30:50,279] Trial 41 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 1.9369134399306683e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.07676743274441097, 'model3_loss': 'squared_hinge', 'meta_C': 1.0917470713049682, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  42: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:30:50,383] Trial 42 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 1.223393191706513e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.41154092500478706, 'model3_loss': 'squared_hinge', 'meta_C': 2.4745585366763967, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  42: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:30:50,383] Trial 42 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 1.223393191706513e-05, 'model2_solver': 'eigen', 'model2_shrinkage': 'auto', 'model3_C': 0.41154092500478706, 'model3_loss': 'squared_hinge', 'meta_C': 2.4745585366763967, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  43: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:30:50,826] Trial 43 finished with value: 0.0 and parameters: {'model1_reg_param': 0.00018832689881752448, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.021958367350932, 'model3_loss': 'squared_hinge', 'meta_C': 0.6075013141662351, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  43: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:30:50,826] Trial 43 finished with value: 0.0 and parameters: {'model1_reg_param': 0.00018832689881752448, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.021958367350932, 'model3_loss': 'squared_hinge', 'meta_C': 0.6075013141662351, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  44: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:30:58,491] Trial 44 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 4.9541504559740504e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.14114595850750042, 'model3_loss': 'squared_hinge', 'meta_C': 1.463109365627233, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  44: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:30:58,491] Trial 44 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 4.9541504559740504e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.14114595850750042, 'model3_loss': 'squared_hinge', 'meta_C': 1.463109365627233, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  45: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:31:04,464] Trial 45 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 1.7827602135522785e-05, 'model2_solver': 'svd', 'model3_C': 0.0660080174879951, 'model3_loss': 'squared_hinge', 'meta_C': 3.526054617670845, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  45: Accuracy = 0.5323\n",
      "[I 2025-10-25 11:31:04,464] Trial 45 finished with value: 0.5322777101096224 and parameters: {'model1_reg_param': 1.7827602135522785e-05, 'model2_solver': 'svd', 'model3_C': 0.0660080174879951, 'model3_loss': 'squared_hinge', 'meta_C': 3.526054617670845, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  46: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:31:07,559] Trial 46 finished with value: 0.0 and parameters: {'model1_reg_param': 0.0006837110413029732, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.040424983940627705, 'model3_loss': 'hinge', 'meta_C': 0.4674512091756161, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  46: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:31:07,559] Trial 46 finished with value: 0.0 and parameters: {'model1_reg_param': 0.0006837110413029732, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.040424983940627705, 'model3_loss': 'hinge', 'meta_C': 0.4674512091756161, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  47: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:31:15,095] Trial 47 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 0.0003814260349267717, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.0268133411923566, 'model3_loss': 'squared_hinge', 'meta_C': 0.9127206836425862, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  47: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:31:15,095] Trial 47 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 0.0003814260349267717, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.0268133411923566, 'model3_loss': 'squared_hinge', 'meta_C': 0.9127206836425862, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  48: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:31:22,678] Trial 48 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.0013226500756671222, 'model2_solver': 'svd', 'model3_C': 0.013794704887596564, 'model3_loss': 'hinge', 'meta_C': 0.19293428983577282, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  48: Accuracy = 0.5201\n",
      "[I 2025-10-25 11:31:22,678] Trial 48 finished with value: 0.5200974421437271 and parameters: {'model1_reg_param': 0.0013226500756671222, 'model2_solver': 'svd', 'model3_C': 0.013794704887596564, 'model3_loss': 'hinge', 'meta_C': 0.19293428983577282, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  49: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:31:25,869] Trial 49 finished with value: 0.0 and parameters: {'model1_reg_param': 9.871405516291015e-05, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.1244992112084238, 'model3_loss': 'hinge', 'meta_C': 0.007860422074209674, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  49: FAILED - The leading minor of order 9 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "[I 2025-10-25 11:31:25,869] Trial 49 finished with value: 0.0 and parameters: {'model1_reg_param': 9.871405516291015e-05, 'model2_solver': 'eigen', 'model2_shrinkage': None, 'model3_C': 0.1244992112084238, 'model3_loss': 'hinge', 'meta_C': 0.007860422074209674, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  50: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:31:33,252] Trial 50 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 3.147349190811361e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.00296796244700458, 'model3_loss': 'squared_hinge', 'meta_C': 1.8897186213543855, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  50: Accuracy = 0.5298\n",
      "[I 2025-10-25 11:31:33,252] Trial 50 finished with value: 0.5298416565164433 and parameters: {'model1_reg_param': 3.147349190811361e-05, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.00296796244700458, 'model3_loss': 'squared_hinge', 'meta_C': 1.8897186213543855, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  51: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:31:40,381] Trial 51 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.00014572662608768343, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.010906923117563435, 'model3_loss': 'hinge', 'meta_C': 5.3105500454274095, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  51: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:31:40,381] Trial 51 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.00014572662608768343, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.010906923117563435, 'model3_loss': 'hinge', 'meta_C': 5.3105500454274095, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  52: Accuracy = 0.5335\n",
      "[I 2025-10-25 11:31:43,809] Trial 52 finished with value: 0.5334957369062119 and parameters: {'model1_reg_param': 0.0004394330321434749, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.005815983190135043, 'model3_loss': 'hinge', 'meta_C': 4.122215193297449, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  52: Accuracy = 0.5335\n",
      "[I 2025-10-25 11:31:43,809] Trial 52 finished with value: 0.5334957369062119 and parameters: {'model1_reg_param': 0.0004394330321434749, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.005815983190135043, 'model3_loss': 'hinge', 'meta_C': 4.122215193297449, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  53: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:31:45,526] Trial 53 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.0002250608098313061, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.2510709815660268, 'model3_loss': 'hinge', 'meta_C': 7.505232799435368, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  53: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:31:45,526] Trial 53 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.0002250608098313061, 'model2_solver': 'lsqr', 'model2_shrinkage': None, 'model3_C': 0.2510709815660268, 'model3_loss': 'hinge', 'meta_C': 7.505232799435368, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  54: Accuracy = 0.5274\n",
      "[I 2025-10-25 11:31:46,837] Trial 54 finished with value: 0.5274056029232643 and parameters: {'model1_reg_param': 0.00017293041980220806, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.030256833468878093, 'model3_loss': 'hinge', 'meta_C': 1.7703514934272238, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  54: Accuracy = 0.5274\n",
      "[I 2025-10-25 11:31:46,837] Trial 54 finished with value: 0.5274056029232643 and parameters: {'model1_reg_param': 0.00017293041980220806, 'model2_solver': 'lsqr', 'model2_shrinkage': 'auto', 'model3_C': 0.030256833468878093, 'model3_loss': 'hinge', 'meta_C': 1.7703514934272238, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  55: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:47,335] Trial 55 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 4.532724362597799e-05, 'model2_solver': 'svd', 'model3_C': 0.0016348638356276232, 'model3_loss': 'hinge', 'meta_C': 2.8408582556431874, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  55: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:47,335] Trial 55 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 4.532724362597799e-05, 'model2_solver': 'svd', 'model3_C': 0.0016348638356276232, 'model3_loss': 'hinge', 'meta_C': 2.8408582556431874, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  56: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:31:47,813] Trial 56 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 1.7685277068912634e-05, 'model2_solver': 'svd', 'model3_C': 0.0011715893528897788, 'model3_loss': 'hinge', 'meta_C': 2.907870369662605, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  56: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:31:47,813] Trial 56 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 1.7685277068912634e-05, 'model2_solver': 'svd', 'model3_C': 0.0011715893528897788, 'model3_loss': 'hinge', 'meta_C': 2.907870369662605, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  57: Accuracy = 0.5250\n",
      "[I 2025-10-25 11:31:48,599] Trial 57 finished with value: 0.5249695493300852 and parameters: {'model1_reg_param': 4.544539573957819e-05, 'model2_solver': 'svd', 'model3_C': 0.0017526050193607903, 'model3_loss': 'hinge', 'meta_C': 1.5336961546924532, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  57: Accuracy = 0.5250\n",
      "[I 2025-10-25 11:31:48,599] Trial 57 finished with value: 0.5249695493300852 and parameters: {'model1_reg_param': 4.544539573957819e-05, 'model2_solver': 'svd', 'model3_C': 0.0017526050193607903, 'model3_loss': 'hinge', 'meta_C': 1.5336961546924532, 'meta_solver': 'liblinear'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  58: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:49,576] Trial 58 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 7.200264482199324e-05, 'model2_solver': 'svd', 'model3_C': 0.003366455081261577, 'model3_loss': 'hinge', 'meta_C': 9.855551816473332, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  58: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:49,576] Trial 58 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 7.200264482199324e-05, 'model2_solver': 'svd', 'model3_C': 0.003366455081261577, 'model3_loss': 'hinge', 'meta_C': 9.855551816473332, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  59: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:49,972] Trial 59 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 7.073038205568228e-05, 'model2_solver': 'svd', 'model3_C': 0.0010110008760813552, 'model3_loss': 'hinge', 'meta_C': 9.91095590934238, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  59: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:49,972] Trial 59 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 7.073038205568228e-05, 'model2_solver': 'svd', 'model3_C': 0.0010110008760813552, 'model3_loss': 'hinge', 'meta_C': 9.91095590934238, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  60: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:50,405] Trial 60 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 5.810331001826663e-05, 'model2_solver': 'svd', 'model3_C': 0.0010298786341746825, 'model3_loss': 'hinge', 'meta_C': 9.755501112600502, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  60: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:50,405] Trial 60 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 5.810331001826663e-05, 'model2_solver': 'svd', 'model3_C': 0.0010298786341746825, 'model3_loss': 'hinge', 'meta_C': 9.755501112600502, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  61: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:50,976] Trial 61 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 5.830616981170055e-05, 'model2_solver': 'svd', 'model3_C': 0.0010525318610616512, 'model3_loss': 'hinge', 'meta_C': 9.698526283812576, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  61: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:50,976] Trial 61 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 5.830616981170055e-05, 'model2_solver': 'svd', 'model3_C': 0.0010525318610616512, 'model3_loss': 'hinge', 'meta_C': 9.698526283812576, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  62: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:51,999] Trial 62 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 6.983552706677122e-05, 'model2_solver': 'svd', 'model3_C': 0.0032916759427096373, 'model3_loss': 'hinge', 'meta_C': 6.94671775491056, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  62: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:51,999] Trial 62 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 6.983552706677122e-05, 'model2_solver': 'svd', 'model3_C': 0.0032916759427096373, 'model3_loss': 'hinge', 'meta_C': 6.94671775491056, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  63: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:52,600] Trial 63 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 3.9691673193535716e-05, 'model2_solver': 'svd', 'model3_C': 0.0017119779678641393, 'model3_loss': 'hinge', 'meta_C': 7.375435843451793, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  63: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:52,600] Trial 63 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 3.9691673193535716e-05, 'model2_solver': 'svd', 'model3_C': 0.0017119779678641393, 'model3_loss': 'hinge', 'meta_C': 7.375435843451793, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  64: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:31:53,335] Trial 64 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.00011156056261335502, 'model2_solver': 'svd', 'model3_C': 0.0012622239554513953, 'model3_loss': 'hinge', 'meta_C': 4.49877355472913, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  64: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:31:53,335] Trial 64 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.00011156056261335502, 'model2_solver': 'svd', 'model3_C': 0.0012622239554513953, 'model3_loss': 'hinge', 'meta_C': 4.49877355472913, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  65: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:31:54,169] Trial 65 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 7.789704869949337e-05, 'model2_solver': 'svd', 'model3_C': 0.0032474199630097914, 'model3_loss': 'hinge', 'meta_C': 9.632317207654934, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  65: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:31:54,169] Trial 65 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 7.789704869949337e-05, 'model2_solver': 'svd', 'model3_C': 0.0032474199630097914, 'model3_loss': 'hinge', 'meta_C': 9.632317207654934, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  66: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:55,065] Trial 66 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 2.7845605247803517e-05, 'model2_solver': 'svd', 'model3_C': 0.002271797815010344, 'model3_loss': 'hinge', 'meta_C': 3.345708981077705, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  66: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:31:55,065] Trial 66 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 2.7845605247803517e-05, 'model2_solver': 'svd', 'model3_C': 0.002271797815010344, 'model3_loss': 'hinge', 'meta_C': 3.345708981077705, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  67: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:56,059] Trial 67 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 2.4619423705708142e-05, 'model2_solver': 'svd', 'model3_C': 0.001916327307590949, 'model3_loss': 'hinge', 'meta_C': 3.1840120691358775, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  67: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:56,059] Trial 67 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 2.4619423705708142e-05, 'model2_solver': 'svd', 'model3_C': 0.001916327307590949, 'model3_loss': 'hinge', 'meta_C': 3.1840120691358775, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  68: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:31:56,885] Trial 68 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 3.6648050313540096e-05, 'model2_solver': 'svd', 'model3_C': 0.007578665475674648, 'model3_loss': 'hinge', 'meta_C': 2.2201147527398537, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  68: Accuracy = 0.5384\n",
      "[I 2025-10-25 11:31:56,885] Trial 68 finished with value: 0.53836784409257 and parameters: {'model1_reg_param': 3.6648050313540096e-05, 'model2_solver': 'svd', 'model3_C': 0.007578665475674648, 'model3_loss': 'hinge', 'meta_C': 2.2201147527398537, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  69: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:31:58,877] Trial 69 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 1.0400700591837087e-05, 'model2_solver': 'svd', 'model3_C': 7.882394072090051, 'model3_loss': 'hinge', 'meta_C': 6.260407909078005, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  69: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:31:58,877] Trial 69 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 1.0400700591837087e-05, 'model2_solver': 'svd', 'model3_C': 7.882394072090051, 'model3_loss': 'hinge', 'meta_C': 6.260407909078005, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  70: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:59,810] Trial 70 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.000322309170650762, 'model2_solver': 'svd', 'model3_C': 0.0025083294993324015, 'model3_loss': 'hinge', 'meta_C': 4.68420881862442, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  70: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:31:59,810] Trial 70 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.000322309170650762, 'model2_solver': 'svd', 'model3_C': 0.0025083294993324015, 'model3_loss': 'hinge', 'meta_C': 4.68420881862442, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  71: Accuracy = 0.5445\n",
      "[I 2025-10-25 11:32:00,226] Trial 71 finished with value: 0.5444579780755177 and parameters: {'model1_reg_param': 5.6922541662432025e-05, 'model2_solver': 'svd', 'model3_C': 0.00100950588161032, 'model3_loss': 'hinge', 'meta_C': 3.592947679479216, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  71: Accuracy = 0.5445\n",
      "[I 2025-10-25 11:32:00,226] Trial 71 finished with value: 0.5444579780755177 and parameters: {'model1_reg_param': 5.6922541662432025e-05, 'model2_solver': 'svd', 'model3_C': 0.00100950588161032, 'model3_loss': 'hinge', 'meta_C': 3.592947679479216, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  72: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:00,782] Trial 72 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 5.0745498974355476e-05, 'model2_solver': 'svd', 'model3_C': 0.00144607879951869, 'model3_loss': 'hinge', 'meta_C': 3.510991723496924, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  72: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:00,782] Trial 72 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 5.0745498974355476e-05, 'model2_solver': 'svd', 'model3_C': 0.00144607879951869, 'model3_loss': 'hinge', 'meta_C': 3.510991723496924, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  73: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:01,693] Trial 73 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 2.8507530863911437e-05, 'model2_solver': 'svd', 'model3_C': 0.003739545305067995, 'model3_loss': 'hinge', 'meta_C': 2.469123497540139, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  73: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:01,693] Trial 73 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 2.8507530863911437e-05, 'model2_solver': 'svd', 'model3_C': 0.003739545305067995, 'model3_loss': 'hinge', 'meta_C': 2.469123497540139, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  74: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:32:02,575] Trial 74 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 2.773550378098155e-05, 'model2_solver': 'svd', 'model3_C': 0.0037521903496274813, 'model3_loss': 'hinge', 'meta_C': 0.018197010134596216, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  74: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:32:02,575] Trial 74 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 2.773550378098155e-05, 'model2_solver': 'svd', 'model3_C': 0.0037521903496274813, 'model3_loss': 'hinge', 'meta_C': 0.018197010134596216, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  75: Accuracy = 0.5274\n",
      "[I 2025-10-25 11:32:03,312] Trial 75 finished with value: 0.5274056029232643 and parameters: {'model1_reg_param': 0.012830134197372925, 'model2_solver': 'svd', 'model3_C': 0.0055844552146707095, 'model3_loss': 'hinge', 'meta_C': 0.7523578323504155, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  75: Accuracy = 0.5274\n",
      "[I 2025-10-25 11:32:03,312] Trial 75 finished with value: 0.5274056029232643 and parameters: {'model1_reg_param': 0.012830134197372925, 'model2_solver': 'svd', 'model3_C': 0.0055844552146707095, 'model3_loss': 'hinge', 'meta_C': 0.7523578323504155, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  76: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:04,146] Trial 76 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 2.156966917645645e-05, 'model2_solver': 'svd', 'model3_C': 0.002336127888921541, 'model3_loss': 'hinge', 'meta_C': 2.1694496373875176, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  76: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:04,146] Trial 76 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 2.156966917645645e-05, 'model2_solver': 'svd', 'model3_C': 0.002336127888921541, 'model3_loss': 'hinge', 'meta_C': 2.1694496373875176, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  77: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:32:04,843] Trial 77 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 3.282915002452699e-05, 'model2_solver': 'svd', 'model3_C': 0.00469122068671377, 'model3_loss': 'hinge', 'meta_C': 6.213606726629745, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  77: Accuracy = 0.5371\n",
      "[I 2025-10-25 11:32:04,843] Trial 77 finished with value: 0.5371498172959805 and parameters: {'model1_reg_param': 3.282915002452699e-05, 'model2_solver': 'svd', 'model3_C': 0.00469122068671377, 'model3_loss': 'hinge', 'meta_C': 6.213606726629745, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  78: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:32:05,697] Trial 78 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.09808738670935396, 'model2_solver': 'svd', 'model3_C': 0.008653580605421055, 'model3_loss': 'hinge', 'meta_C': 1.3156753119238889, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  78: Accuracy = 0.5347\n",
      "[I 2025-10-25 11:32:05,697] Trial 78 finished with value: 0.5347137637028014 and parameters: {'model1_reg_param': 0.09808738670935396, 'model2_solver': 'svd', 'model3_C': 0.008653580605421055, 'model3_loss': 'hinge', 'meta_C': 1.3156753119238889, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  79: Accuracy = 0.4896\n",
      "[I 2025-10-25 11:32:06,565] Trial 79 finished with value: 0.48964677222898906 and parameters: {'model1_reg_param': 1.6021779947832147e-05, 'model2_solver': 'svd', 'model3_C': 0.0020543467254827094, 'model3_loss': 'hinge', 'meta_C': 0.054238957778222824, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  79: Accuracy = 0.4896\n",
      "[I 2025-10-25 11:32:06,565] Trial 79 finished with value: 0.48964677222898906 and parameters: {'model1_reg_param': 1.6021779947832147e-05, 'model2_solver': 'svd', 'model3_C': 0.0020543467254827094, 'model3_loss': 'hinge', 'meta_C': 0.054238957778222824, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  80: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:07,135] Trial 80 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.005881179142023631, 'model2_solver': 'svd', 'model3_C': 0.0013937068144189038, 'model3_loss': 'hinge', 'meta_C': 4.707414719239131, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  80: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:07,135] Trial 80 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.005881179142023631, 'model2_solver': 'svd', 'model3_C': 0.0013937068144189038, 'model3_loss': 'hinge', 'meta_C': 4.707414719239131, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  81: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:07,816] Trial 81 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.007229762303403076, 'model2_solver': 'svd', 'model3_C': 0.0013930441653746425, 'model3_loss': 'hinge', 'meta_C': 4.801638045704328, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  81: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:07,816] Trial 81 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.007229762303403076, 'model2_solver': 'svd', 'model3_C': 0.0013930441653746425, 'model3_loss': 'hinge', 'meta_C': 4.801638045704328, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  82: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:08,732] Trial 82 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.029788951939328, 'model2_solver': 'svd', 'model3_C': 0.003077677959869865, 'model3_loss': 'hinge', 'meta_C': 3.793336874977411, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  82: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:08,732] Trial 82 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.029788951939328, 'model2_solver': 'svd', 'model3_C': 0.003077677959869865, 'model3_loss': 'hinge', 'meta_C': 3.793336874977411, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  83: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:09,641] Trial 83 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.005211532228508266, 'model2_solver': 'svd', 'model3_C': 0.003949622463439179, 'model3_loss': 'hinge', 'meta_C': 7.35728482628898, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  83: Accuracy = 0.5408\n",
      "[I 2025-10-25 11:32:09,641] Trial 83 finished with value: 0.5408038976857491 and parameters: {'model1_reg_param': 0.005211532228508266, 'model2_solver': 'svd', 'model3_C': 0.003949622463439179, 'model3_loss': 'hinge', 'meta_C': 7.35728482628898, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  84: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:32:10,191] Trial 84 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 9.115709083659022e-05, 'model2_solver': 'svd', 'model3_C': 0.001269381418008415, 'model3_loss': 'hinge', 'meta_C': 0.003605810296627764, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  84: Accuracy = 0.4811\n",
      "[I 2025-10-25 11:32:10,191] Trial 84 finished with value: 0.48112058465286234 and parameters: {'model1_reg_param': 9.115709083659022e-05, 'model2_solver': 'svd', 'model3_C': 0.001269381418008415, 'model3_loss': 'hinge', 'meta_C': 0.003605810296627764, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  85: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:11,002] Trial 85 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0022620664033521625, 'model2_solver': 'svd', 'model3_C': 0.002484960908218777, 'model3_loss': 'hinge', 'meta_C': 2.424623672450924, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  85: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:11,002] Trial 85 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0022620664033521625, 'model2_solver': 'svd', 'model3_C': 0.002484960908218777, 'model3_loss': 'hinge', 'meta_C': 2.424623672450924, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  86: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:11,827] Trial 86 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.00198218964843834, 'model2_solver': 'svd', 'model3_C': 0.0024377994934447447, 'model3_loss': 'hinge', 'meta_C': 2.3885250455463853, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  86: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:11,827] Trial 86 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.00198218964843834, 'model2_solver': 'svd', 'model3_C': 0.0024377994934447447, 'model3_loss': 'hinge', 'meta_C': 2.3885250455463853, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  87: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:12,619] Trial 87 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.003822737360264117, 'model2_solver': 'svd', 'model3_C': 0.0026006065210507434, 'model3_loss': 'hinge', 'meta_C': 2.2138398380862485, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  87: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:12,619] Trial 87 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.003822737360264117, 'model2_solver': 'svd', 'model3_C': 0.0026006065210507434, 'model3_loss': 'hinge', 'meta_C': 2.2138398380862485, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  88: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:13,244] Trial 88 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.002202583843906767, 'model2_solver': 'svd', 'model3_C': 0.0021459170781945192, 'model3_loss': 'hinge', 'meta_C': 5.721817114122028, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  88: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:13,244] Trial 88 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.002202583843906767, 'model2_solver': 'svd', 'model3_C': 0.0021459170781945192, 'model3_loss': 'hinge', 'meta_C': 5.721817114122028, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  89: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:13,717] Trial 89 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0027311038160148723, 'model2_solver': 'svd', 'model3_C': 0.0014559821187069921, 'model3_loss': 'hinge', 'meta_C': 2.9002778982087545, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  89: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:13,717] Trial 89 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0027311038160148723, 'model2_solver': 'svd', 'model3_C': 0.0014559821187069921, 'model3_loss': 'hinge', 'meta_C': 2.9002778982087545, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  90: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:14,532] Trial 90 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.006505513198113363, 'model2_solver': 'svd', 'model3_C': 0.006265928531146492, 'model3_loss': 'hinge', 'meta_C': 1.8770630532704846, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  90: Accuracy = 0.5396\n",
      "[I 2025-10-25 11:32:14,532] Trial 90 finished with value: 0.5395858708891595 and parameters: {'model1_reg_param': 0.006505513198113363, 'model2_solver': 'svd', 'model3_C': 0.006265928531146492, 'model3_loss': 'hinge', 'meta_C': 1.8770630532704846, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  91: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:15,381] Trial 91 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.004538597056206878, 'model2_solver': 'svd', 'model3_C': 0.002702881796601161, 'model3_loss': 'hinge', 'meta_C': 2.363260630420216, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  91: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:15,381] Trial 91 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.004538597056206878, 'model2_solver': 'svd', 'model3_C': 0.002702881796601161, 'model3_loss': 'hinge', 'meta_C': 2.363260630420216, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  92: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:32:16,098] Trial 92 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 0.001921321154650797, 'model2_solver': 'svd', 'model3_C': 0.001822884717434395, 'model3_loss': 'hinge', 'meta_C': 0.9511053373038485, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  92: Accuracy = 0.5286\n",
      "[I 2025-10-25 11:32:16,098] Trial 92 finished with value: 0.5286236297198539 and parameters: {'model1_reg_param': 0.001921321154650797, 'model2_solver': 'svd', 'model3_C': 0.001822884717434395, 'model3_loss': 'hinge', 'meta_C': 0.9511053373038485, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  93: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:32:16,883] Trial 93 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 0.0010688722479524754, 'model2_solver': 'svd', 'model3_C': 0.0025378288264985387, 'model3_loss': 'hinge', 'meta_C': 1.3304276102608996, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  93: Accuracy = 0.5311\n",
      "[I 2025-10-25 11:32:16,883] Trial 93 finished with value: 0.5310596833130329 and parameters: {'model1_reg_param': 0.0010688722479524754, 'model2_solver': 'svd', 'model3_C': 0.0025378288264985387, 'model3_loss': 'hinge', 'meta_C': 1.3304276102608996, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  94: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:17,229] Trial 94 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0028716018588559405, 'model2_solver': 'svd', 'model3_C': 0.001024225139845949, 'model3_loss': 'hinge', 'meta_C': 4.255708720422284, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  94: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:17,229] Trial 94 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.0028716018588559405, 'model2_solver': 'svd', 'model3_C': 0.001024225139845949, 'model3_loss': 'hinge', 'meta_C': 4.255708720422284, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  95: Accuracy = 0.5457\n",
      "[I 2025-10-25 11:32:18,042] Trial 95 finished with value: 0.5456760048721072 and parameters: {'model1_reg_param': 0.009470146351965749, 'model2_solver': 'svd', 'model3_C': 0.0034403522343227143, 'model3_loss': 'hinge', 'meta_C': 1.8994785789574222, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  95: Accuracy = 0.5457\n",
      "[I 2025-10-25 11:32:18,042] Trial 95 finished with value: 0.5456760048721072 and parameters: {'model1_reg_param': 0.009470146351965749, 'model2_solver': 'svd', 'model3_C': 0.0034403522343227143, 'model3_loss': 'hinge', 'meta_C': 1.8994785789574222, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  96: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:32:18,805] Trial 96 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.009405087994215331, 'model2_solver': 'svd', 'model3_C': 0.0032738718911909316, 'model3_loss': 'hinge', 'meta_C': 0.5168975834304688, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  96: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:32:18,805] Trial 96 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.009405087994215331, 'model2_solver': 'svd', 'model3_C': 0.0032738718911909316, 'model3_loss': 'hinge', 'meta_C': 0.5168975834304688, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  97: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:32:19,634] Trial 97 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.0015227413370567592, 'model2_solver': 'svd', 'model3_C': 0.0038728772454432697, 'model3_loss': 'hinge', 'meta_C': 0.3220870624034132, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  97: Accuracy = 0.5359\n",
      "[I 2025-10-25 11:32:19,634] Trial 97 finished with value: 0.535931790499391 and parameters: {'model1_reg_param': 0.0015227413370567592, 'model2_solver': 'svd', 'model3_C': 0.0038728772454432697, 'model3_loss': 'hinge', 'meta_C': 0.3220870624034132, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  98: Accuracy = 0.5432\n",
      "[I 2025-10-25 11:32:20,262] Trial 98 finished with value: 0.5432399512789281 and parameters: {'model1_reg_param': 0.02160157886849832, 'model2_solver': 'svd', 'model3_C': 0.0012525661365789123, 'model3_loss': 'hinge', 'meta_C': 8.028300050980596, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  98: Accuracy = 0.5432\n",
      "[I 2025-10-25 11:32:20,262] Trial 98 finished with value: 0.5432399512789281 and parameters: {'model1_reg_param': 0.02160157886849832, 'model2_solver': 'svd', 'model3_C': 0.0012525661365789123, 'model3_loss': 'hinge', 'meta_C': 8.028300050980596, 'meta_solver': 'lbfgs'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "Trial  99: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:20,719] Trial 99 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.020852068055200096, 'model2_solver': 'svd', 'model3_C': 0.001298061444128477, 'model3_loss': 'hinge', 'meta_C': 8.455623415433818, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "\n",
      "================================================================================\n",
      "Optimization completed!\n",
      "================================================================================\n",
      "Trial  99: Accuracy = 0.5420\n",
      "[I 2025-10-25 11:32:20,719] Trial 99 finished with value: 0.5420219244823387 and parameters: {'model1_reg_param': 0.020852068055200096, 'model2_solver': 'svd', 'model3_C': 0.001298061444128477, 'model3_loss': 'hinge', 'meta_C': 8.455623415433818, 'meta_solver': 'saga'}. Best is trial 28 with value: 0.5456760048721072.\n",
      "\n",
      "================================================================================\n",
      "Optimization completed!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna hyperparameter optimization\n",
    "print(\"=\"*80)\n",
    "print(f\"Starting Optuna hyperparameter optimization...\")\n",
    "print(f\"Configuration to optimize:\")\n",
    "print(f\"  Base Learners: {TOP_3_MODELS}\")\n",
    "print(f\"  Meta-Learner: {BEST_META_LEARNER_NAME}\")\n",
    "print(f\"  Number of Trials: {N_TRIALS}\")\n",
    "print(f\"  CV Folds: {CV_FOLDS}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Create Optuna study with TPE sampler (Tree-structured Parzen Estimator)\n",
    "# TPE is efficient for Bayesian optimization\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximize accuracy\n",
    "    sampler=TPESampler(seed=RANDOM_STATE)  # For reproducibility\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(\n",
    "    objective, \n",
    "    n_trials=N_TRIALS,\n",
    "    timeout=TIMEOUT,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"Optimization completed!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edee9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Trial Results:\n",
      "  Trial Number: 28\n",
      "  Best Accuracy: 0.5457\n",
      "\n",
      "Best Hyperparameters:\n",
      "  model1_reg_param: 8.526718006684437e-05\n",
      "  model2_solver: lsqr\n",
      "  model2_shrinkage: None\n",
      "  model3_C: 0.020491419535060576\n",
      "  model3_loss: hinge\n",
      "  meta_C: 0.622062829368627\n",
      "  meta_solver: lbfgs\n",
      "\n",
      "Optimization Statistics:\n",
      "  Total Trials: 100\n",
      "  Complete Trials: 100\n",
      "  Pruned Trials: 0\n",
      "  Failed Trials: 0\n",
      "\n",
      "================================================================================\n",
      "Variable 'BEST_HYPERPARAMETERS' created with optimized parameters\n",
      "This variable contains all hyperparameters for base learners and meta-learner\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display optimization results and store in variables for later use\n",
    "best_trial = study.best_trial\n",
    "\n",
    "# Store best hyperparameters in variable for use in subsequent notebooks\n",
    "BEST_HYPERPARAMETERS = best_trial.params.copy()\n",
    "\n",
    "print(f\"\\nBest Trial Results:\")\n",
    "print(f\"  Trial Number: {best_trial.number}\")\n",
    "print(f\"  Best Accuracy: {best_trial.value:.4f}\")\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "for key, value in BEST_HYPERPARAMETERS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Display optimization statistics\n",
    "print(f\"\\nOptimization Statistics:\")\n",
    "print(f\"  Total Trials: {len(study.trials)}\")\n",
    "print(f\"  Complete Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "print(f\"  Pruned Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "print(f\"  Failed Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Variable 'BEST_HYPERPARAMETERS' created with optimized parameters\")\n",
    "print(f\"This variable contains all hyperparameters for base learners and meta-learner\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1819f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Training final optimized ensemble...\n",
      "================================================================================\n",
      "  Base Learner 1: QuadraticDiscriminantAnalysis\n",
      "    Parameters: {'reg_param': 8.526718006684437e-05}\n",
      "  Base Learner 2: LinearDiscriminantAnalysis\n",
      "    Parameters: {'solver': 'lsqr', 'shrinkage': None}\n",
      "  Base Learner 3: LinearSVC\n",
      "    Parameters: {'C': 0.020491419535060576, 'loss': 'hinge'}\n",
      "  Meta-Learner: LogisticRegression\n",
      "    Parameters: {'C': 0.622062829368627, 'solver': 'lbfgs'}\n",
      "\n",
      "================================================================================\n",
      "Final Optimized Ensemble Performance:\n",
      "  Test Accuracy: 0.5384\n",
      "================================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Down (0)       0.62      0.29      0.40       426\n",
      "      Up (1)       0.51      0.81      0.63       395\n",
      "\n",
      "    accuracy                           0.54       821\n",
      "   macro avg       0.56      0.55      0.51       821\n",
      "weighted avg       0.57      0.54      0.51       821\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Variables created for later use:\n",
      "  BEST_HYPERPARAMETERS: Dictionary of all optimized hyperparameters\n",
      "  OPTIMIZED_BASE_LEARNERS_CONFIG: List of base learner configurations\n",
      "  OPTIMIZED_META_LEARNER_CONFIG: Meta-learner configuration\n",
      "  FINAL_OPTIMIZED_ENSEMBLE: Trained stacking ensemble model\n",
      "  OPTIMIZED_ACCURACY: Final test accuracy (0.5384)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Final Optimized Ensemble Performance:\n",
      "  Test Accuracy: 0.5384\n",
      "================================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Down (0)       0.62      0.29      0.40       426\n",
      "      Up (1)       0.51      0.81      0.63       395\n",
      "\n",
      "    accuracy                           0.54       821\n",
      "   macro avg       0.56      0.55      0.51       821\n",
      "weighted avg       0.57      0.54      0.51       821\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Variables created for later use:\n",
      "  BEST_HYPERPARAMETERS: Dictionary of all optimized hyperparameters\n",
      "  OPTIMIZED_BASE_LEARNERS_CONFIG: List of base learner configurations\n",
      "  OPTIMIZED_META_LEARNER_CONFIG: Meta-learner configuration\n",
      "  FINAL_OPTIMIZED_ENSEMBLE: Trained stacking ensemble model\n",
      "  OPTIMIZED_ACCURACY: Final test accuracy (0.5384)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Train final optimized ensemble with best hyperparameters\n",
    "# Store optimized models in variables for later use\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training final optimized ensemble...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_params = BEST_HYPERPARAMETERS\n",
    "\n",
    "# Reconstruct base learners with best hyperparameters\n",
    "base_learners_optimized = []\n",
    "OPTIMIZED_BASE_LEARNERS_CONFIG = []  # Store configuration for later use\n",
    "\n",
    "for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "    prefix = f'model{i}_'\n",
    "    # Extract parameters for this model\n",
    "    model_params = {k.replace(prefix, ''): v for k, v in best_params.items() if k.startswith(prefix)}\n",
    "    model_instance = instantiate_model(model_name, model_params)\n",
    "    base_learners_optimized.append((f'model_{i}', model_instance))\n",
    "    \n",
    "    # Store configuration\n",
    "    OPTIMIZED_BASE_LEARNERS_CONFIG.append({\n",
    "        'name': model_name,\n",
    "        'parameters': model_params\n",
    "    })\n",
    "    \n",
    "    print(f\"  Base Learner {i}: {model_name}\")\n",
    "    print(f\"    Parameters: {model_params}\")\n",
    "\n",
    "# Reconstruct meta-learner with best hyperparameters\n",
    "meta_prefix = 'meta_'\n",
    "meta_params = {k.replace(meta_prefix, ''): v for k, v in best_params.items() if k.startswith(meta_prefix)}\n",
    "meta_learner_optimized = instantiate_model(BEST_META_LEARNER_NAME, meta_params)\n",
    "\n",
    "# Store meta-learner configuration\n",
    "OPTIMIZED_META_LEARNER_CONFIG = {\n",
    "    'name': BEST_META_LEARNER_NAME,\n",
    "    'parameters': meta_params\n",
    "}\n",
    "\n",
    "print(f\"  Meta-Learner: {BEST_META_LEARNER_NAME}\")\n",
    "print(f\"    Parameters: {meta_params}\")\n",
    "\n",
    "# Build final stacking ensemble\n",
    "FINAL_OPTIMIZED_ENSEMBLE = StackingClassifier(\n",
    "    estimators=base_learners_optimized,\n",
    "    final_estimator=meta_learner_optimized,\n",
    "    cv=CV_FOLDS,\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "\n",
    "# Train on full training set\n",
    "FINAL_OPTIMIZED_ENSEMBLE.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_optimized = FINAL_OPTIMIZED_ENSEMBLE.predict(X_test)\n",
    "OPTIMIZED_ACCURACY = accuracy_score(y_test, y_pred_optimized)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Final Optimized Ensemble Performance:\")\n",
    "print(f\"  Test Accuracy: {OPTIMIZED_ACCURACY:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimized, target_names=['Down (0)', 'Up (1)']))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Variables created for later use:\")\n",
    "print(f\"  BEST_HYPERPARAMETERS: Dictionary of all optimized hyperparameters\")\n",
    "print(f\"  OPTIMIZED_BASE_LEARNERS_CONFIG: List of base learner configurations\")\n",
    "print(f\"  OPTIMIZED_META_LEARNER_CONFIG: Meta-learner configuration\")\n",
    "print(f\"  FINAL_OPTIMIZED_ENSEMBLE: Trained stacking ensemble model\")\n",
    "print(f\"  OPTIMIZED_ACCURACY: Final test accuracy ({OPTIMIZED_ACCURACY:.4f})\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36804b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving optimization results...\n",
      "  Best hyperparameters saved to: ../data/processed/metrics/best_params_stacking.json\n",
      "  Human-readable version saved to: ../data/processed/metrics/best_params_stacking.txt\n",
      "\n",
      "Optimization complete! Results ready for notebook 06.\n"
     ]
    }
   ],
   "source": [
    "# Save best hyperparameters for future use and reproducibility\n",
    "print(\"Saving optimization results...\")\n",
    "\n",
    "# Prepare complete configuration for saving\n",
    "optimization_results = {\n",
    "    'base_learners': TOP_3_MODELS,\n",
    "    'meta_learner': BEST_META_LEARNER_NAME,\n",
    "    'best_accuracy': OPTIMIZED_ACCURACY,\n",
    "    'n_trials': N_TRIALS,\n",
    "    'best_trial_number': best_trial.number,\n",
    "    'hyperparameters': BEST_HYPERPARAMETERS,\n",
    "    'base_learners_config': OPTIMIZED_BASE_LEARNERS_CONFIG,\n",
    "    'meta_learner_config': OPTIMIZED_META_LEARNER_CONFIG\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "os.makedirs(os.path.dirname(BEST_PARAMS_OUTPUT), exist_ok=True)\n",
    "with open(BEST_PARAMS_OUTPUT, 'w') as f:\n",
    "    json.dump(optimization_results, f, indent=2)\n",
    "\n",
    "print(f\"  Best hyperparameters saved to: {BEST_PARAMS_OUTPUT}\")\n",
    "\n",
    "# Also save a human-readable version\n",
    "txt_output = BEST_PARAMS_OUTPUT.replace('.json', '.txt')\n",
    "with open(txt_output, 'w') as f:\n",
    "    f.write(f\"Optuna Hyperparameter Optimization Results\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Base Learners: {', '.join(TOP_3_MODELS)}\\n\")\n",
    "    f.write(f\"Meta-Learner: {BEST_META_LEARNER_NAME}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Optimization Configuration:\\n\")\n",
    "    f.write(f\"  Total Trials: {N_TRIALS}\\n\")\n",
    "    f.write(f\"  CV Folds: {CV_FOLDS}\\n\")\n",
    "    f.write(f\"  Best Trial: {best_trial.number}\\n\")\n",
    "    f.write(f\"  Best Accuracy: {OPTIMIZED_ACCURACY:.4f}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Best Hyperparameters:\\n\")\n",
    "    for key, value in BEST_HYPERPARAMETERS.items():\n",
    "        f.write(f\"  {key}: {value}\\n\")\n",
    "\n",
    "print(f\"  Human-readable version saved to: {txt_output}\")\n",
    "print(f\"\\nOptimization complete! Results ready for notebook 06.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Final Summary\n",
    "print(\"=\"*80)\n",
    "print(\"NOTEBOOK 05 COMPLETE - Hyperparameter Optimization\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Completion time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nKey Results:\")\n",
    "print(f\"  Optimization Method: Bayesian (TPE Sampler)\")\n",
    "print(f\"  Total Trials: {N_TRIALS}\")\n",
    "print(f\"  Best Trial: {best_trial.number}\")\n",
    "print(f\"  Optimized Accuracy: {OPTIMIZED_ACCURACY:.4f}\")\n",
    "print(f\"\\nBase Learners: {', '.join(TOP_3_MODELS)}\")\n",
    "print(f\"Meta-Learner: {BEST_META_LEARNER_NAME}\")\n",
    "print(f\"\\nOutputs Saved:\")\n",
    "print(f\"  - {BEST_PARAMS_OUTPUT}\")\n",
    "print(f\"  - {txt_output}\")\n",
    "print(f\"\\nVariables Available for Notebook 06:\")\n",
    "print(f\"  - BEST_HYPERPARAMETERS\")\n",
    "print(f\"  - OPTIMIZED_BASE_LEARNERS_CONFIG\")\n",
    "print(f\"  - OPTIMIZED_META_LEARNER_CONFIG\")\n",
    "print(f\"  - FINAL_OPTIMIZED_ENSEMBLE\")\n",
    "print(f\"  - OPTIMIZED_ACCURACY\")\n",
    "print(f\"  - TOP_3_MODELS\")\n",
    "print(f\"  - BEST_META_LEARNER_NAME\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fc571",
   "metadata": {},
   "source": [
    "## Summary - Variables for Notebook 06\n",
    "\n",
    "The following variables are now available for use in **notebook 06 (SHAP Feature Selection)**:\n",
    "\n",
    "### 1. **BEST_HYPERPARAMETERS** (dict)\n",
    "Dictionary containing all optimized hyperparameters for base learners and meta-learner, discovered through Optuna's Bayesian optimization.\n",
    "\n",
    "### 2. **OPTIMIZED_BASE_LEARNERS_CONFIG** (list)\n",
    "List of dictionaries with base learner names and their optimized parameters. Each entry contains:\n",
    "- `name`: Model class name (e.g., 'QuadraticDiscriminantAnalysis')\n",
    "- `parameters`: Dictionary of optimized hyperparameters for that model\n",
    "\n",
    "### 3. **OPTIMIZED_META_LEARNER_CONFIG** (dict)\n",
    "Dictionary containing the meta-learner configuration:\n",
    "- `name`: Meta-learner class name (e.g., 'LogisticRegression')\n",
    "- `parameters`: Dictionary of optimized hyperparameters\n",
    "\n",
    "### 4. **FINAL_OPTIMIZED_ENSEMBLE** (StackingClassifier)\n",
    "Fully trained stacking ensemble with optimized hyperparameters. Ready for SHAP analysis and prediction.\n",
    "\n",
    "### 5. **OPTIMIZED_ACCURACY** (float)\n",
    "Test accuracy achieved by the optimized ensemble. Use this as baseline for feature selection comparison.\n",
    "\n",
    "### 6. **TOP_3_MODELS** (list)\n",
    "List of the top 3 model names selected from notebook 03, used as base learners in the ensemble.\n",
    "\n",
    "### 7. **BEST_META_LEARNER_NAME** (str)\n",
    "Name of the best meta-learner selected in notebook 04.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready for next step**: These variables will be loaded in notebook 06 for SHAP analysis and feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3a25c8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Hyperparameter optimization successfully completed using Optuna:\n",
    "- Loaded ensemble configuration from Notebooks 03 and 04\n",
    "- Optimized hyperparameters for all 3 base learners\n",
    "- Optimized hyperparameters for the meta-learner\n",
    "- Ran Bayesian optimization with TPE sampler for efficient search\n",
    "- Trained final ensemble with optimal hyperparameters\n",
    "- Saved best configuration for reproducibility\n",
    "\n",
    "**Optimization Configuration:**\n",
    "- Base Learners: Loaded dynamically from Notebook 03 results\n",
    "- Meta-Learner: Loaded from Notebook 04 selection\n",
    "- Trials: 100 (Bayesian optimization)\n",
    "- Search Strategy: Tree-structured Parzen Estimator (TPE)\n",
    "\n",
    "**Variables Created:**\n",
    "The `BEST_HYPERPARAMETERS`, `OPTIMIZED_BASE_LEARNERS_CONFIG`, `OPTIMIZED_META_LEARNER_CONFIG`, `FINAL_OPTIMIZED_ENSEMBLE`, and `OPTIMIZED_ACCURACY` variables store the complete optimization results and trained model for use in Notebook 06.\n",
    "\n",
    "**Results:**\n",
    "- Best hyperparameters saved to JSON and text files\n",
    "- Optimized ensemble ready for feature selection and trading analysis\n",
    "- All parameters reproducible for future experiments\n",
    "\n",
    "**Key Findings:**\n",
    "- Hyperparameter optimization can significantly improve ensemble performance\n",
    "- Bayesian optimization efficiently explores complex parameter spaces\n",
    "- Configuration properly wired from previous notebooks\n",
    "\n",
    "## Next Steps\n",
    "Proceed to `06_shap_feature_selection.ipynb` to:\n",
    "- Load the optimized ensemble configuration (BEST_HYPERPARAMETERS and variables)\n",
    "- Calculate SHAP values for feature importance\n",
    "- Identify most impactful features\n",
    "- Perform feature selection based on SHAP analysis\n",
    "- Retrain model with selected features\n",
    "- Compare performance: all features vs selected features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
