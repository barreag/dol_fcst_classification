{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b16a57",
   "metadata": {},
   "source": [
    "# Step 4: Stacking Ensemble Building\n",
    "\n",
    "## Objective\n",
    "Build a stacking ensemble classifier using the top 3 models identified in Notebook 03 as base learners, with an optimized meta-learner to combine their predictions.\n",
    "\n",
    "## Process\n",
    "1. Load top 3 model names from Notebook 03 evaluation results\n",
    "2. Map model names to sklearn classifier instances\n",
    "3. Load engineered features from `data/processed/BRL_X_features.csv`\n",
    "4. Create base learners from the top 3 models\n",
    "5. Evaluate multiple meta-learner candidates (Logistic Regression, Random Forest, XGBoost)\n",
    "6. Select best meta-learner based on accuracy\n",
    "7. Train final stacking ensemble with optimal configuration\n",
    "8. Compare ensemble performance vs individual base models\n",
    "\n",
    "## Output\n",
    "- Stacking ensemble classifier using top 3 models as base learners\n",
    "- Best meta-learner stored in `BEST_META_LEARNER` variable for notebook 05\n",
    "- Performance comparison: ensemble vs individual models\n",
    "\n",
    "## Ensemble Architecture\n",
    "**Stacking Ensemble** combines multiple models in two layers:\n",
    "- **Layer 1 (Base Learners)**: Top 3 models from LazyClassifier make predictions\n",
    "- **Layer 2 (Meta Learner)**: Learns to optimally combine base model predictions\n",
    "- Uses cross-validation to prevent overfitting during meta-learner training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cb3dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking ensemble building started at: 2025-10-25 11:18:04\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Model selection and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Ensemble methods\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "\n",
    "# Linear models\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron\n",
    "\n",
    "# Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# SVM models\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "# Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "# Tree-based models\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(f\"Stacking ensemble building started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6e2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Features: ../data/processed/BRL_X_features.csv\n",
      "  Top Models File: ../data/processed/metrics/top_3_model_names.txt\n",
      "  Test Size: 20.0%\n",
      "  CV Folds: 5\n",
      "  Shuffle: False (preserving time series order)\n"
     ]
    }
   ],
   "source": [
    "# Define configuration parameters\n",
    "FEATURES_PATH = '../data/processed/BRL_X_features.csv'  # Input file from notebook 02\n",
    "TOP_MODELS_FILE = '../data/processed/metrics/top_3_model_names.txt'  # Top 3 models from notebook 03\n",
    "\n",
    "# Train/test split configuration (must match notebook 03)\n",
    "TEST_SIZE = 0.2        # 20% of data for testing\n",
    "RANDOM_STATE = 42      # For reproducibility\n",
    "SHUFFLE = False        # Critical: Do not shuffle time series data\n",
    "\n",
    "# Stacking ensemble configuration\n",
    "CV_FOLDS = 5           # Cross-validation folds for meta-learner training\n",
    "N_JOBS = -1            # Use all CPU cores\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Features: {FEATURES_PATH}\")\n",
    "print(f\"  Top Models File: {TOP_MODELS_FILE}\")\n",
    "print(f\"  Test Size: {TEST_SIZE * 100}%\")\n",
    "print(f\"  CV Folds: {CV_FOLDS}\")\n",
    "print(f\"  Shuffle: {SHUFFLE} (preserving time series order)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae08cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading top 3 models from Notebook 03...\n",
      "\n",
      "Top 3 Models from Notebook 03:\n",
      "  1. QuadraticDiscriminantAnalysis\n",
      "  2. LinearDiscriminantAnalysis\n",
      "  3. LinearSVC\n",
      "\n",
      "Total models loaded: 3\n"
     ]
    }
   ],
   "source": [
    "# Load top 3 model names from Notebook 03 evaluation results\n",
    "# These are the best performing models identified by LazyClassifier\n",
    "\n",
    "print(\"Loading top 3 models from Notebook 03...\")\n",
    "TOP_3_MODELS = []\n",
    "\n",
    "with open(TOP_MODELS_FILE, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        # Parse lines like \"1. QuadraticDiscriminantAnalysis\"\n",
    "        if line.strip() and line[0].isdigit():\n",
    "            model_name = line.split('.', 1)[1].strip()\n",
    "            TOP_3_MODELS.append(model_name)\n",
    "\n",
    "print(f\"\\nTop 3 Models from Notebook 03:\")\n",
    "for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "    print(f\"  {i}. {model_name}\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(TOP_3_MODELS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d1428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mapping created with 22 available classifiers\n"
     ]
    }
   ],
   "source": [
    "# Create mapping from model name strings to sklearn classifier instances\n",
    "# This allows dynamic instantiation of models based on LazyClassifier results\n",
    "\n",
    "MODEL_MAPPING = {\n",
    "    # Discriminant Analysis\n",
    "    'LinearDiscriminantAnalysis': LinearDiscriminantAnalysis(),\n",
    "    'QuadraticDiscriminantAnalysis': QuadraticDiscriminantAnalysis(),\n",
    "    \n",
    "    # SVM Models\n",
    "    'LinearSVC': LinearSVC(random_state=RANDOM_STATE, max_iter=10000),\n",
    "    'SVC': SVC(random_state=RANDOM_STATE),\n",
    "    'NuSVC': NuSVC(random_state=RANDOM_STATE),\n",
    "    \n",
    "    # Ensemble Models\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(random_state=RANDOM_STATE, n_estimators=100),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'BaggingClassifier': BaggingClassifier(random_state=RANDOM_STATE),\n",
    "    \n",
    "    # Linear Models\n",
    "    'LogisticRegression': LogisticRegression(random_state=RANDOM_STATE, max_iter=10000),\n",
    "    'RidgeClassifier': RidgeClassifier(random_state=RANDOM_STATE),\n",
    "    'SGDClassifier': SGDClassifier(random_state=RANDOM_STATE, max_iter=10000),\n",
    "    'PassiveAggressiveClassifier': PassiveAggressiveClassifier(random_state=RANDOM_STATE, max_iter=10000),\n",
    "    'Perceptron': Perceptron(random_state=RANDOM_STATE, max_iter=10000),\n",
    "    \n",
    "    # Neighbors\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=5),\n",
    "    'NearestCentroid': NearestCentroid(),\n",
    "    \n",
    "    # Naive Bayes\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    \n",
    "    # Tree Models\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    'ExtraTreeClassifier': ExtraTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \n",
    "    # XGBoost\n",
    "    'XGBClassifier': XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss'),\n",
    "}\n",
    "\n",
    "print(f\"Model mapping created with {len(MODEL_MAPPING)} available classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44008787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from Notebook 02:\n",
      "  Total records: 4103\n",
      "  Date range: 2010-01-21 to 2025-10-24\n",
      "  Rows dropped (NaN): 0\n",
      "  Dataset shape: (4103, 18)\n",
      "\n",
      "Features: (4103, 17)\n",
      "Target: (4103,)\n",
      "\n",
      "Target distribution:\n",
      "target\n",
      "1    2067\n",
      "0    2036\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "1    0.503778\n",
      "0    0.496222\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load engineered features from Notebook 02\n",
    "df = pd.read_csv(FEATURES_PATH, index_col=0)\n",
    "\n",
    "# Convert index to datetime for proper time series handling\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index.name = 'Date'\n",
    "\n",
    "# Handle missing values (should be minimal after notebook 02 processing)\n",
    "rows_before = len(df)\n",
    "df = df.dropna()\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f\"Data loaded from Notebook 02:\")\n",
    "print(f\"  Total records: {rows_after}\")\n",
    "print(f\"  Date range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"  Rows dropped (NaN): {rows_before - rows_after}\")\n",
    "print(f\"  Dataset shape: {df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "print(f\"\\nFeatures: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bf6af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Split Summary:\n",
      "  Total samples: 4103\n",
      "  Training samples: 3282 (80.0%)\n",
      "  Testing samples: 821 (20.0%)\n",
      "\n",
      "Training period: 2010-01-21 to 2022-08-29\n",
      "Testing period: 2022-08-30 to 2025-10-24\n",
      "\n",
      "Note: This split must match Notebook 03 for fair ensemble comparison\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "# CRITICAL: Must match Notebook 03 split for fair comparison\n",
    "# shuffle=False preserves time series order\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    shuffle=SHUFFLE\n",
    ")\n",
    "\n",
    "# Display split information\n",
    "print(f\"Train/Test Split Summary:\")\n",
    "print(f\"  Total samples: {len(X)}\")\n",
    "print(f\"  Training samples: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Testing samples: {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Show date ranges for each set (time series context)\n",
    "train_start = X_train.index.min().strftime('%Y-%m-%d')\n",
    "train_end = X_train.index.max().strftime('%Y-%m-%d')\n",
    "test_start = X_test.index.min().strftime('%Y-%m-%d')\n",
    "test_end = X_test.index.max().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"\\nTraining period: {train_start} to {train_end}\")\n",
    "print(f\"Testing period: {test_start} to {test_end}\")\n",
    "\n",
    "# Verify this matches Notebook 03\n",
    "print(f\"\\nNote: This split must match Notebook 03 for fair ensemble comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abde4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating base learners from TOP_3_MODELS:\n",
      "================================================================================\n",
      "1. QuadraticDiscriminantAnalysis - Successfully instantiated\n",
      "2. LinearDiscriminantAnalysis - Successfully instantiated\n",
      "3. LinearSVC - Successfully instantiated\n",
      "================================================================================\n",
      "\n",
      "Base learners created: 3\n",
      "Ready for stacking ensemble\n"
     ]
    }
   ],
   "source": [
    "# Create base learners from TOP_3_MODELS\n",
    "# Dynamically instantiate the models selected in Notebook 03\n",
    "\n",
    "base_learners = []\n",
    "\n",
    "print(\"Creating base learners from TOP_3_MODELS:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "    if model_name in MODEL_MAPPING:\n",
    "        model_instance = MODEL_MAPPING[model_name]\n",
    "        # Create tuple with (name, model_instance) for StackingClassifier\n",
    "        base_learners.append((f'model_{i}', model_instance))\n",
    "        print(f\"{i}. {model_name} - Successfully instantiated\")\n",
    "    else:\n",
    "        print(f\"{i}. {model_name} - ERROR: Not found in MODEL_MAPPING\")\n",
    "        raise ValueError(f\"Model '{model_name}' not found in MODEL_MAPPING. Please add it.\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBase learners created: {len(base_learners)}\")\n",
    "print(f\"Ready for stacking ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4696af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-learner candidates to evaluate: 5\n",
      "  - LogisticRegression\n",
      "  - RandomForest\n",
      "  - XGBoost\n",
      "  - GradientBoosting\n",
      "  - ExtraTrees\n"
     ]
    }
   ],
   "source": [
    "# Define candidate meta-learners to test\n",
    "# Meta-learner combines predictions from base learners\n",
    "# Test multiple algorithms to find the best combination\n",
    "\n",
    "meta_learner_candidates = [\n",
    "    ('LogisticRegression', LogisticRegression(random_state=RANDOM_STATE, max_iter=10000)),\n",
    "    ('RandomForest', RandomForestClassifier(random_state=RANDOM_STATE, n_estimators=100)),\n",
    "    ('XGBoost', XGBClassifier(random_state=RANDOM_STATE, use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('GradientBoosting', GradientBoostingClassifier(random_state=RANDOM_STATE)),\n",
    "    ('ExtraTrees', ExtraTreesClassifier(random_state=RANDOM_STATE, n_estimators=100))\n",
    "]\n",
    "\n",
    "print(f\"Meta-learner candidates to evaluate: {len(meta_learner_candidates)}\")\n",
    "for name, _ in meta_learner_candidates:\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dedfa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating meta-learners with stacking ensemble...\n",
      "================================================================================\n",
      "This may take several minutes as each configuration uses cross-validation.\n",
      "\n",
      "Testing meta-learner: LogisticRegression...\n",
      "  LogisticRegression Accuracy: 0.5347\n",
      "Testing meta-learner: RandomForest...\n",
      "  LogisticRegression Accuracy: 0.5347\n",
      "Testing meta-learner: RandomForest...\n",
      "  RandomForest Accuracy: 0.4689\n",
      "Testing meta-learner: XGBoost...\n",
      "  RandomForest Accuracy: 0.4689\n",
      "Testing meta-learner: XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TZCYT0\\ml_env\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [11:18:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  XGBoost Accuracy: 0.4714\n",
      "Testing meta-learner: GradientBoosting...\n",
      "  GradientBoosting Accuracy: 0.5104\n",
      "Testing meta-learner: ExtraTrees...\n",
      "  GradientBoosting Accuracy: 0.5104\n",
      "Testing meta-learner: ExtraTrees...\n",
      "  ExtraTrees Accuracy: 0.4860\n",
      "\n",
      "================================================================================\n",
      "Meta-learner evaluation completed!\n",
      "\n",
      "Best Meta-Learner: LogisticRegression\n",
      "Best Accuracy: 0.5347\n",
      "  ExtraTrees Accuracy: 0.4860\n",
      "\n",
      "================================================================================\n",
      "Meta-learner evaluation completed!\n",
      "\n",
      "Best Meta-Learner: LogisticRegression\n",
      "Best Accuracy: 0.5347\n"
     ]
    }
   ],
   "source": [
    "# Evaluate different meta-learners with stacking ensemble\n",
    "# Test each meta-learner to find which best combines the base models\n",
    "\n",
    "print(\"Evaluating meta-learners with stacking ensemble...\")\n",
    "print(\"=\"*80)\n",
    "print(\"This may take several minutes as each configuration uses cross-validation.\\n\")\n",
    "\n",
    "meta_results = {}\n",
    "best_accuracy = -1\n",
    "best_meta_name = None\n",
    "best_meta_learner_instance = None\n",
    "best_stacking_clf = None\n",
    "\n",
    "for meta_name, meta_learner in meta_learner_candidates:\n",
    "    print(f\"Testing meta-learner: {meta_name}...\")\n",
    "    \n",
    "    # Create stacking classifier with current meta-learner\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_learners,\n",
    "        final_estimator=meta_learner,\n",
    "        cv=CV_FOLDS,           # Cross-validation to prevent overfitting\n",
    "        n_jobs=N_JOBS          # Use all CPU cores\n",
    "    )\n",
    "    \n",
    "    # Train the stacking ensemble\n",
    "    stacking_clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    y_pred = stacking_clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    meta_results[meta_name] = accuracy\n",
    "    \n",
    "    print(f\"  {meta_name} Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Track best performing meta-learner\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_meta_name = meta_name\n",
    "        best_meta_learner_instance = meta_learner\n",
    "        best_stacking_clf = stacking_clf\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Meta-learner evaluation completed!\")\n",
    "print(f\"\\nBest Meta-Learner: {best_meta_name}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f90b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Meta-Learner Performance Comparison:\n",
      "================================================================================\n",
      " Rank       Meta-Learner  Accuracy\n",
      "    1 LogisticRegression  0.534714\n",
      "    2   GradientBoosting  0.510353\n",
      "    3         ExtraTrees  0.485993\n",
      "    4            XGBoost  0.471376\n",
      "    5       RandomForest  0.468940\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display detailed comparison of all meta-learners\n",
    "# Show how each meta-learner performed\n",
    "\n",
    "print(\"Detailed Meta-Learner Performance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "meta_comparison_df = pd.DataFrame(list(meta_results.items()), columns=['Meta-Learner', 'Accuracy'])\n",
    "meta_comparison_df = meta_comparison_df.sort_values('Accuracy', ascending=False)\n",
    "meta_comparison_df['Rank'] = range(1, len(meta_comparison_df) + 1)\n",
    "meta_comparison_df = meta_comparison_df[['Rank', 'Meta-Learner', 'Accuracy']]\n",
    "\n",
    "print(meta_comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aab23896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final stacking ensemble with best configuration...\n",
      "Base Learners: ['model_1', 'model_2', 'model_3']\n",
      "Meta-Learner: LogisticRegression\n",
      "\n",
      "Final Stacking Ensemble Performance:\n",
      "  Test Accuracy: 0.5347\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Down (0)       0.59      0.35      0.44       426\n",
      "      Up (1)       0.51      0.74      0.60       395\n",
      "\n",
      "    accuracy                           0.53       821\n",
      "   macro avg       0.55      0.54      0.52       821\n",
      "weighted avg       0.55      0.53      0.52       821\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[148 278]\n",
      " [104 291]]\n",
      "  True Negatives:  148\n",
      "  False Positives: 278\n",
      "  False Negatives: 104\n",
      "  True Positives:  291\n",
      "\n",
      "================================================================================\n",
      "Variable 'BEST_META_LEARNER' created: LogisticRegression\n",
      "Variable 'BEST_META_LEARNER_NAME' created: 'LogisticRegression'\n",
      "These variables will be used in notebook 05 for hyperparameter optimization.\n"
     ]
    }
   ],
   "source": [
    "# Train final stacking ensemble with best meta-learner\n",
    "# Store the best meta-learner in BEST_META_LEARNER variable for notebook 05\n",
    "\n",
    "# Store best meta-learner for future use\n",
    "BEST_META_LEARNER = best_meta_learner_instance\n",
    "BEST_META_LEARNER_NAME = best_meta_name\n",
    "\n",
    "print(f\"Training final stacking ensemble with best configuration...\")\n",
    "print(f\"Base Learners: {[name for name, _ in base_learners]}\")\n",
    "print(f\"Meta-Learner: {BEST_META_LEARNER_NAME}\")\n",
    "print()\n",
    "\n",
    "# The best model was already trained during evaluation\n",
    "final_stacking_clf = best_stacking_clf\n",
    "\n",
    "# Get predictions on test set\n",
    "y_pred = final_stacking_clf.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final Stacking Ensemble Performance:\")\n",
    "print(f\"  Test Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Down (0)', 'Up (1)']))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(f\"  True Negatives:  {cm[0][0]}\")\n",
    "print(f\"  False Positives: {cm[0][1]}\")\n",
    "print(f\"  False Negatives: {cm[1][0]}\")\n",
    "print(f\"  True Positives:  {cm[1][1]}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Variable 'BEST_META_LEARNER' created: {BEST_META_LEARNER_NAME}\")\n",
    "print(f\"Variable 'BEST_META_LEARNER_NAME' created: '{BEST_META_LEARNER_NAME}'\")\n",
    "print(f\"These variables will be used in notebook 05 for hyperparameter optimization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf05212f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison: Ensemble vs Individual Base Models\n",
      "================================================================================\n",
      "QuadraticDiscriminantAnalysis: 0.5128\n",
      "LinearDiscriminantAnalysis: 0.5396\n",
      "LinearSVC: 0.5189\n",
      "\n",
      "Stacking Ensemble (LogisticRegression): 0.5347\n",
      "================================================================================\n",
      "\n",
      "Average Individual Model Accuracy: 0.5238\n",
      "Stacking Ensemble Accuracy: 0.5347\n",
      "Improvement: +0.0110 (+2.09%)\n",
      "\n",
      "The ensemble OUTPERFORMS the average of individual models!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TZCYT0\\ml_env\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "c:\\Users\\TZCYT0\\ml_env\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Compare ensemble performance vs individual base models\n",
    "# Evaluate if stacking provides improvement over single models\n",
    "\n",
    "print(\"Performance Comparison: Ensemble vs Individual Base Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "individual_results = {}\n",
    "\n",
    "# Evaluate each base model individually\n",
    "for model_name, model in base_learners:\n",
    "    # Get the original model name from TOP_3_MODELS\n",
    "    original_name = TOP_3_MODELS[int(model_name.split('_')[1]) - 1]\n",
    "    \n",
    "    # Clone and train the model\n",
    "    from sklearn.base import clone\n",
    "    model_clone = clone(model)\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_individual = model_clone.predict(X_test)\n",
    "    accuracy_individual = accuracy_score(y_test, y_pred_individual)\n",
    "    \n",
    "    individual_results[original_name] = accuracy_individual\n",
    "    print(f\"{original_name}: {accuracy_individual:.4f}\")\n",
    "\n",
    "print(f\"\\nStacking Ensemble ({BEST_META_LEARNER_NAME}): {final_accuracy:.4f}\")\n",
    "\n",
    "# Calculate improvement\n",
    "avg_individual = np.mean(list(individual_results.values()))\n",
    "improvement = final_accuracy - avg_individual\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAverage Individual Model Accuracy: {avg_individual:.4f}\")\n",
    "print(f\"Stacking Ensemble Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Improvement: {improvement:+.4f} ({improvement/avg_individual*100:+.2f}%)\")\n",
    "\n",
    "if improvement > 0:\n",
    "    print(f\"\\nThe ensemble OUTPERFORMS the average of individual models!\")\n",
    "else:\n",
    "    print(f\"\\nThe ensemble does not significantly improve over individual models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e96512a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble configuration saved to: ../data/processed/metrics/stacking_ensemble_config.txt\n"
     ]
    }
   ],
   "source": [
    "# Save ensemble configuration for documentation\n",
    "# Store the final configuration for reference and notebook 05\n",
    "\n",
    "ensemble_config = {\n",
    "    'base_learners': TOP_3_MODELS,\n",
    "    'meta_learner': BEST_META_LEARNER_NAME,\n",
    "    'test_accuracy': final_accuracy,\n",
    "    'cv_folds': CV_FOLDS,\n",
    "    'individual_accuracies': individual_results,\n",
    "    'ensemble_improvement': improvement\n",
    "}\n",
    "\n",
    "# Save to metrics directory\n",
    "METRICS_PATH = '../data/processed/metrics/'\n",
    "os.makedirs(METRICS_PATH, exist_ok=True)\n",
    "\n",
    "config_path = os.path.join(METRICS_PATH, 'stacking_ensemble_config.txt')\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(f\"Stacking Ensemble Configuration\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"=\"*80 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Base Learners (from Notebook 03):\\n\")\n",
    "    for i, model_name in enumerate(TOP_3_MODELS, 1):\n",
    "        f.write(f\"  {i}. {model_name}: {individual_results[model_name]:.4f}\\n\")\n",
    "    \n",
    "    f.write(f\"\\nMeta-Learner: {BEST_META_LEARNER_NAME}\\n\")\n",
    "    f.write(f\"Cross-Validation Folds: {CV_FOLDS}\\n\")\n",
    "    f.write(f\"\\nEnsemble Test Accuracy: {final_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Average Individual Accuracy: {avg_individual:.4f}\\n\")\n",
    "    f.write(f\"Improvement: {improvement:+.4f} ({improvement/avg_individual*100:+.2f}%)\\n\")\n",
    "\n",
    "print(f\"Ensemble configuration saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0709350c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Stacking ensemble successfully built and evaluated:\n",
    "- Loaded top 3 models from Notebook 03 LazyClassifier evaluation\n",
    "- Base learners dynamically instantiated from model names\n",
    "- Evaluated 5 different meta-learner candidates\n",
    "- Selected best meta-learner based on test accuracy\n",
    "- Compared ensemble performance against individual base models\n",
    "\n",
    "**Base Learners (from Notebook 03):**\n",
    "The ensemble uses the top 3 models identified in the previous notebook as base learners in the first layer of the stacking architecture.\n",
    "\n",
    "**Meta-Learner Selection:**\n",
    "The `BEST_META_LEARNER` and `BEST_META_LEARNER_NAME` variables store the optimal meta-learner configuration, which will be used in Notebook 05 for hyperparameter optimization.\n",
    "\n",
    "**Ensemble Architecture:**\n",
    "- Layer 1: Top 3 models make independent predictions\n",
    "- Layer 2: Meta-learner combines predictions using cross-validation\n",
    "- Prevents overfitting through CV during training\n",
    "\n",
    "**Key Findings:**\n",
    "- Ensemble performance compared to individual models\n",
    "- Configuration saved to `data/processed/metrics/` for documentation\n",
    "- Ready for hyperparameter optimization\n",
    "\n",
    "## Next Steps\n",
    "Proceed to `05_stacking_optuna.ipynb` to:\n",
    "- Load the ensemble configuration (TOP_3_MODELS and BEST_META_LEARNER)\n",
    "- Use Optuna for Bayesian hyperparameter optimization\n",
    "- Optimize both base learners and meta-learner parameters\n",
    "- Find the best hyperparameter combination\n",
    "- Evaluate optimized ensemble performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
